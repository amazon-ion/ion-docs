// Keep document header lines together!
// Certain attributes must be defined here to work correctly.
// https://docs.asciidoctor.org/asciidoc/latest/document/header
:doctitle: Ion 1.0 Denotational Semantics
:author: Todd V. Jonker
:email: jonker@amazon.com
// Document header ends at first blank line.

// TODO This is generating invalid DocBook: no <year> just <holder>
:copyright: 2023 Amazon.com Inc. or Affiliates (“Amazon”)
:doctype: article
:stem: latexmath

// Now custom attributes and styles.
:modeltex: tex/ion-model.tex

include::styles.adoc[]


== Introduction

When Ion 1.0 was created in 2007, its documentation consisted of a handful of
wiki pages that were more of a user guide than a specification, intended to be
easily consumed by users and other stakeholders.  Early implementations were
built by Ion's designers and by people close to the project, so tight
communication (and a growing test suite) made up for the lack of formality.
Over time, however, the spec's narrative approach showed its weakness as gaps,
errors, and inconsistencies repeatedly surfaced.

This was most problematic around symbols and symbol tables, which involve
numerous constraints and subtle algorithms intended to make
handling of Ion data robust in the face of incomplete
shared symbol table information.
More generally, mental models diverged around the semantic distinction between
the so-called "`raw layer`" (containing version markers, local symbol tables, and
symbol IDs) and the "`application layer`" (from which those things are removed).

These issues compounded during the development of Ion 1.1, when the attempt
to introduce a template mechanism fell squarely into this zone of
uncertainty, where misalignment on terminology and semantics caused frustration
and delay.  As the design grew to include a full-blown macro system, we knew
we needed a more robust way to communicate--to ourselves and to others--about the
proposed feature's semantics and behavior.  When a day at the whiteboard sketching a
formal model of the raw-layer semantics led to a-ha moments and bug discoveries
within the spec, we knew this would be a fruitful approach.

This work-in-progress document is the continuation of that sketch.
It defines the _denotational semantics_ of the Ion data language,
mapping Ion syntax to typed _domains_ in lambda calculus and using mathematical
functions to define the meaning of the computational elements that translate
that syntax into application data.

Our primary goal is to illuminate and clarify the _evaluation_ of an Ion document,
the process by which certain Ion encoding artifacts are consumed and/or
transformed, ultimately producing the user's data.
In Ion 1.0 these artifacts include version markers, local symbol table
directives, and symbol tokens.
Ion 1.1 introduces much more sophisticated encoding features--new directives,
modules, encoding expressions--and this document is intended to lay the
groundwork for a formal presentation of those features.

TIP: We assume a basic familiarity with lambda calculus, though not much more
than the ability to recognize that stem:[\lambda xy.\mbox{\it body}]
represents a function of two arguments.

IMPORTANT: This document is very much a work in progress.
We crave feedback on its structure, terminology, explanation, notation,
correctness, completeness, formatting...


=== A Primer

Lambda calculus is a mathematical formalism for computing that uses only
anonymous functions (i.e., abstractions or lambda), terms (i.e., variables),
and application (i.e., invocation of functions).
This minimal set of operations has been shown to be Turing complete and can
encode mathematical concepts such as Booleans and natural numbers (and the
operations on them).
It is similarly straightforward to model data types such as _sequences_ and
_tuples_ using lambda calculus.

With these primitives we define types of lambda-calculus values as _domains_.
For our purposes, a _domain_ can be thought of as a set of tagged
values, where each value knows what type it is.  This allows the math to be
strongly-typed, at the expense of some bookkeeping to convert values across
domains.

Pure lambda calculus is challenging to read, so we use quite a few conventions
in our notation to "`pretty print`" various functions.
We also use conventions around the names of functions and variables to help
distinguish their roles and clarify their types.
For instance, we write domain names in *BoldCamelCase* and function arguments in
italic or even Greek letters.

Our first fundamental domain stem:[\mbox{\bf B}] denotes Boolean values.
It has two elements, the constants *true* and *false*.
We test Boolean values with a function
stem:[\mbox{\it if}(b, e_1, e_2)], where
stem:[b \in \mbox{\bf B}], which we pretty-print as
stem:[
\mbox{{\bf if} $b$\:{\bf then}\:$e_1$\:{\bf else}\:$e_2$ {\bf endif}}
].  We assume the presence of related Boolean operators _and_ (stem:[\wedge]),
_or_ (stem:[\vee]) and _not_ (stem:[\lnot]).

Our second fundamental domain, *I*, denotes integer values, which comes along
with the obvious arithmetic operators.

Given some domain *D*, we write **D**{asterisk} to mean the domain of sequences
of *D*.
We pretty-print such values between angle brackets stem:[\langle...\rangle],
for example,
stem:[\langle\mbox{\bf true}, \mbox{\bf false}\rangle \in \mbox{\bf B}^{\ast}].
To make variable names somewhat self-describing, we use asterisks there too,
as in stem:[d^\ast \in \mbox{\bf D}^\ast].
We concatenate sequences with stem:[\S]; to push the element _d_ onto the front
of sequence stem:[d^{\ast}] we can write stem:[\langle d \rangle\S d^{\ast}].
To extract an individual element of sequence
stem:[d^{\ast} = \langle e_0, e_1, ..., e_n\rangle] we write
stem:[d^{\ast}\!\downarrow_{i} = e_i].
To discard the first _i_ elements of a sequence, we write
stem:[d^{\ast}\!\dagger i = \langle e_i, ..., e_n\rangle].
Finally, we write stem:[\#d^{\ast}] to mean the number of items in the sequence
stem:[d^{\ast}].

Similarly, we write stem:[\mbox{\bf D?}] to mean the domain of sequences of
exactly zero or one *D*.
We check whether such an "`option`" (optional value) contains an element by
writing stem:[\mbox{\it v}\interrobang].
When that's true, we can extract the wrapped element by writing stem:[\mbox{\it v}!].

For domains *D* and *E*, we write stem:[\mbox{\bf D} + \mbox{\bf E}] to mean the
disjoint sum of domains *D* and *E*.
We write stem:[\mbox{\bf Sum} \equiv \mbox{\bf D} + \mbox{\bf E}] to define *Sum*
to be that disjunction, and then every element of *Sum*
is an element of _either_ *D* _or_ *E*.
Elements of sum domains are effectively "`tagged`", so we know which component
domain they come from, and we can project or "`lower`" (that is, downcast) a value
stem:[v \in \mbox{\bf Sum}] back into its component domain via
stem:[v\mid_{\mbox{\scriptsize\bf D}}], assuming stem:[v \in \mbox{\bf D}].
Conversely, we can inject or "`lift`" (that is, upcast or wrap) a value into
*Sum* using the
function stem:[\mbox{\it{in}\small \mbox{\bf Sum}}(\mbox{\it v\/})],
assuming stem:[v \in \mbox{\bf D} \vee v \in \mbox{\bf E}].

We write stem:[\mbox{\bf Prod} \equiv \mbox{\bf D} \times \mbox{\bf E}] to
define *Prod* to be the Cartesian product of *D* and *E*.
These are tuples, effectively constrained  sequences containing first some
stem:[d \in \mbox{\bf D}] and then some stem:[e \in \mbox{\bf E}].
We construct them by tagging a sequence:
stem:[\mbox{\it{in}\small\bf Prod}(\langle d, e \rangle)].
To extract elements from a tuple we can overload the stem:[\downarrow]
operator, so that when stem:[p \in \mbox{\bf Prod}] we have
stem:[p \downarrow_{1} \in \mbox{\bf D}] and
stem:[p \downarrow_{2} \in \mbox{\bf E}].
To improve readability, we'll usually introduce additional overloads
addressing tuple fields by name, rather than by index.

Perhaps stretching credibility, we assume another primitive domain, *Unicode*,
denoting Unicode strings.
While we have not explicitly modeled it as such, this is just a sequence of
Unicode code points, effectively **I**{asterisk}.

We'll also define domains describing the input and output types of functions.
For example,
stem:[\mbox{\bf A} \times \mbox{\bf B} \rightarrow \mbox{\bf C}]
is the domain of two-argument functions that accept an element of *A* and
an element of *B* and return an element of *C*.

// TODO: function-definition syntax

In some cases our functions make use of local variables.  The special syntax
stem:[\mbox{\bf let}\: v = e_1 \: \mbox{\bf in}\: e_2]
means that _v_ is bound to the value of stem:[e_1] within the scope of
expression stem:[e_2].  The *letrec* form is similar, except the variable is
bound within _both_ stem:[e_1] and stem:[e_2], enabling recursive definitions.



=== A Roadmap

At a high level, the goal of our model is to define how an Ion processor turns
the syntax within an Ion document into data meaningful to some application.
To maintain this focus, we abstract over the details of how Ion parses the
wire-level octets.
Using the domain *Document* to denote the octets of Ion-formatted data, and
the domain *Value* to model a resulting application datum, we can formalize our
goal in the form of a function domain:

[{denotation}]
++++
include::{modeltex}[tag=Evaluator]
++++

:fn-module: footnote:[We use the Ion 1.1 term "`shared module`" rather than \
"`shared symbol table`" to align with the domain model, which is \
forward-compatible with the future features.  \
What's most important to know is that modules are generalizations of symbol \
tables, so a shared symbol table _is_ a shared module.]

That is, given a document and a catalog (a collection
of shared modules{fn-module}), we produce a sequence of application values.

// TODO Discuss expansion vs evaluation?

We now set upon the task of implementing such a function by way of a formal
mathematical model.
Here's how we'll reach that goal:

* xref:datamodel[xrefstyle=short] defines the domain *Value* and a number of
subdomains that collectively
specify the Ion data model--that is, the set of values that an Ion document can
encode.
We then ease into denotational functions by implementing some
useful operators over this data.

* xref:syntaxmodel[xrefstyle=short] defines the domains representing the
structure of Ion syntax, before expansion and evaluation are performed.
It also defines a mechanism for abstracting over the parsing of **Document**s.

* xref:expansion[xrefstyle=short] visits each corner of the syntax model,
incrementally defining layers of functions that expand abstract syntax into
Ion data **Value**s.

// TODO rephrase/restructure?

* xref:symtabs[xrefstyle=short] specifies the evaluation of encoding directives,
the compilation of local symbol tables, and the responsibilities of a *Catalog*.

* xref:issues[xrefstyle=short] documents the known defects with the model in its
current draft.


.Under the Covers
****
While this document presents its model using fairly conventional denotational
semantics notation, this is no mere whiteboard math: the equations here are in
fact pretty-printed views of executable code.  Expressed using Ion S-expressions
(of course) in a small domain-specific language, the code is strongly typed
and dynamically validated, with a proper test suite and code coverage tooling.
In a meaningful sense, this document presents a real implementation of Ion
evaluation.

Here's an example:
----
(fn mk_Evaluator ((p Parser) -> Evaluator)
  (mk_fn Evaluator (d c)
    (let [(p0 (p d)),
          (r0 (tuple Environment c IVM_1_0 (SymToks_for_IVM IVM_1_0))),
          (k0 (mk_fn TContinuation (r vs) vs))]
      (TE_ParseStream p0 r0 k0))))
----

The code is rendered into stem:[\mbox{\LaTeX}] fragments by a custom library
based on Christian Queinnec's
https://lip6.fr/Christian.Queinnec/WWW/l2t.html[l2t]
(formerly known as LiSP2TeX), then ``include``d into an AsciiDoc article
containing the narrative text.
****


[#datamodel]
== The Ion Data Model

We start our model by defining the domain of Ion data.
In other words, what values can be encoded in an Ion document, and what do they
mean?

At a high level, the definition will be unsurprising to those familiar with Ion:

[{denotation}]
++++
include::{modeltex}[tag=Value]
\newline
include::{modeltex}[tag=Content]
++++

An Ion value is a potentially-empty sequence of symbol tokens annotating some
content, which is partitioned into several typed domains.
You'll note the absence of Ion's decimal, float, timestamp,
blob, and clob types; these cannot contain symbols and thus "`pass through`" the
expansion process unchanged.  Since they have little effect on the model other
than to add a bunch of type-cases, we currently omit them for brevity.

We'll take the opportunity to introduce a syntactic habit that we'll use for
tuple domains like *Value*: simple functions that provide access to the tuple's
components by name:

[{denotation}]
++++
include::{modeltex}[tag=Value_annots]
\newline
include::{modeltex}[tag=Value_content]
++++

This notation further overloads the stem:[\downarrow] operator, but everything
here is strongly-typed so things remain unambiguous.

TIP: When we define a function, we include its signature to the right, to be
explicit about the types of the arguments and result.


[id=simple]
=== Simple Values

We'll continue defining our data model with the easy cases: data types that
cannot contain symbols and therefore don't require expansion.

[{denotation}]
++++
include::{modeltex}[tag=DotNull]
\newline
include::{modeltex}[tag=NullNull]
\newline
include::{modeltex}[tag=Bool]
\newline
include::{modeltex}[tag=Int]
\newline
include::{modeltex}[tag=String]
++++

The singleton domain **DotNull** contains only an opaque constant *dotnull*
that we use as a sentinel for the various typed nulls.  Such a thing is the only
option for the **NullNull** domain, where it denotes `null.null`.  The domains
**Bool**, **Int**, and **String** simply combine the obvious primitive
domains with the possibility of null.

While we use a single sentinel value for all nulls, they are still
strongly-typed in the data model, since the sentinel is "`wrapped`" by an
appropriate domain denoting the data type.
For example, if we have a value _v_ such that
stem:[v \in \mbox{\bf Bool} \wedge v \in \mbox{\bf DotNull}]
then we know that _v_ denotes `null.bool`.


=== Symbols

Symbols form the core of this denotation, which would be trivial if we didn't
need to expand symbol addresses into their text.
The following domains define their meaning:

[{denotation}]
++++
include::{modeltex}[tag=Sym0]
\newline
include::{modeltex}[tag=SymTok]
\newline
include::{modeltex}[tag=Symbol]
++++

*Sym0* is a singleton domain containing only an opaque constant named *sym0*.
As we'll see, this is our denotation for the syntactic token `$0`, symbol zero.

:fn-symeq: footnote:[This fails to properly account for absent shared symbols; \
see xref:iss-symeq[xrefstyle=short].]

*SymTok* denotes an expanded symbol token, either a Unicode string or
`$0`{fn-symeq}.
Symbol tokens are used for annotations, field names, and symbol values.

*Symbol* denotes the latter, being either a symbol token or `null.symbol`.


=== Containers

Ion sequences are simple to denote using sequence domains of values, or null.

[{denotation}]
++++
include::{modeltex}[tag=List]
\newline
include::{modeltex}[tag=Sexp]
++++

// TODO note the recursion/reflexivity introduced by using Value?

:fn-structorder: footnote:[This model is subtly incorrect, since its fields \
are ordered within a struct.  See xref:iss-structorder[xrefstyle=short].]

The domain model for structs is not much more complicated: a struct is either
null or a set{fn-structorder} of fields, and a field is a tuple with a symbol
token and a value.

[{denotation}]
++++
include::{modeltex}[tag=Struct]
\newline
include::{modeltex}[tag=Field]
++++

As before, we introduce some helper notation to deconstruct fields:

[{denotation}]
++++
include::{modeltex}[tag=Field_name]
\newline
include::{modeltex}[tag=Field_value]
++++


=== Matching Symbols

Before we turn to the syntax model, let's define some functions that will be
necessary to get from there to here during expansion.

First, we need to be able to compare symbol values and tokens against Unicode
text.  We'll use infix stem:[\cong] (read "`matches`") to notate this operation.
Matching symbol tokens is straightforward: if the given *SymTok* is *Unicode*
then we lower into that domain and compare with the argument.
Otherwise, the token must be *Sym0*, so we return *false*.

[{denotation}]
++++
include::{modeltex}[tag=SymTok_matches]
++++

To match a symbol value, we check whether the *Symbol* is a *SymTok* (as
opposed to *DotNull*) before calling *SymTok*-flavored comparison.

[{denotation}]
++++
include::{modeltex}[tag=Symbol_matches]
++++

We can now check whether a *Value* is a symbol with specific text:

[{denotation}]
++++
include::{modeltex}[tag=Value_is_symbol_matching]
++++

To get data out of a struct by field name, we need a lookup function.
We'll use infix stem:[\odot] (read "`lookup`") to represent this, here with an
asterisk to indicate that multiple values may result:

[{denotation}]
++++
include::{modeltex}[tag=Struct_get]
++++

All that does is unwrap the struct's field sequence, making it easier to recur:

[{denotation}]
++++
include::{modeltex}[tag=Fields_get]
++++

We recur on the tail of the field sequence (stem:[f^{\ast}\dagger 1]) and bind
the results to stem:[v^\ast].
If the current field's name matches _u_, we prepend (stem:[\S]) its value
onto the recursive results.

That function returns the values of all fields with the given name, but it turns
out that our forthcoming use cases for expansion never accept more than one.
Here's a sibling function that signals an error when the lookup is ambiguous:

[{denotation}]
++++
include::{modeltex}[tag=Struct_get1]
++++

Note that this returns a sequence of zero or one *Value* to comply with the
result domain *Value?*.


[#syntaxmodel]
== The Syntax Model

The previous section defines the values presented to an Ion application, or
rather the domain of values that can be encoded into and read from an Ion
document or stream.
Here we define domains denoting the _syntax_ used in such documents.
It is reasonable to think of these domains as representing the abstract syntax
trees coming
out of the Ion parser before doing anything involving symbols and symbol tables.

NOTE: Historically, Ion documents and implementations have referred to this with
various combinations of the words "`system`" or "`raw`" with "`view`" or "`layer`".
The intended (but poorly-specified) connotation was that this is the data visible to
the "`Ion system`", requiring additional processing to generate the "`application`"
or "`user`" view of the document.

The data and syntax models differ primarily in their handling of symbol
tokens, so the domains mirror each other.
We prefix these domain names  with **S** to indicate that they represent syntax.

// TODO  This model abstracts over the concrete syntax, so applies to text and binary

In the syntax model, a symbol token is either text like "``name``" or a symbol
address like `$4`.
Therefore, a *SSymTok* is either a Unicode string or an integer address:

[{denotation}]
++++
include::{modeltex}[tag=SSymTok]
++++

The rest of the syntax model propagates *SSymTok* in place of *SymTok*.
All domains are mirrored except the simple types, which cannot contain symbol tokens.

[{denotation}]
++++
include::{modeltex}[tag=STree]
\newline
include::{modeltex}[tag=SValue]
\newline
include::{modeltex}[tag=SContent]
\newline
include::{modeltex}[tag=SSymbol]
\newline
include::{modeltex}[tag=SList]
\newline
include::{modeltex}[tag=SSexp]
\newline
include::{modeltex}[tag=SStruct]
\newline
include::{modeltex}[tag=SField]
++++

One oddity here is introduction of a syntax-tree domain *STree* _above_
*SValue*, and used in its place within containers.
In Ion 1.0 this extra layer has no benefit, but in Ion 1.1 we need E-expression
syntax alongside general value syntax, where they cannot be annotated.
We include *STree* proactively to avoid refactoring this hierarchy (and
modifying a bunch of functions) later.

As usual, accessor functions:

[{denotation}]
++++
include::{modeltex}[tag=SValue_annots]
\newline
include::{modeltex}[tag=SValue_content]
\newline
include::{modeltex}[tag=SField_name]
\newline
include::{modeltex}[tag=SField_tree]
++++


[id=stx-top]
=== Top Level Syntax

// TODO This should probably focus on IVMs, to not blur expansion and evaluation

The syntax and data models also diverge at the top level of documents, which can
contain __directives__ that are not part of the application-facing data model.
Instead, directives affect the encoding of the data that follows.

Ion 1.0 has two kinds of directives: Ion version markers (IVMs) and local symbol
tables (LSTs).  The latter are simply annotated **SStruct**s that require no
special handling here.  In contrast, IVMs are dedicated syntactic keywords
(opcode in binary); to everyone's confusion, they are not symbols even though
they match the grammar for symbols.

Since we cannot express IVMs within *STree*, we model these top-level-only
features through separate domain.
A top-level syntax tree can be any general syntax tree, or an IVM:

[{denotation}]
++++
include::{modeltex}[tag=TSTree]
++++

IVMs are straightforward:

[{denotation}]
++++
include::{modeltex}[tag=IVM]
\newline
include::{modeltex}[tag=IVM_1_0]
++++

We'll want to compare IVMs, so here's an equality operator:

[{denotation}]
++++
include::{modeltex}[tag=IVM_eq]
++++


[id=parsing]
=== Parsing

These syntax domains represent the output of an Ion parser as it steps through
a document.  The semantics of parsing would be far too complex to approach in
this article, so instead we assume the presence of a parsing function with the
following signature:

[{denotation}]
++++
include::{modeltex}[tag=Document]
\newline
include::{modeltex}[tag=Parser]
++++

Perhaps surprisingly, a *Parser* doesn't produce **TSTree**{asterisk}.
This is another proactive step toward Ion 1.1, where a directive can change the
Ion version and/or install user-defined macros, both of which affect the
interpretation of later bytes in the document.
To achieve this, we need a feedback loop from the evaluator to the parser after
each top-level syntax tree.

[{denotation}]
++++
include::{modeltex}[tag=ParseStream]
\newline
include::{modeltex}[tag=ParseStep]
\newline\newline
include::{modeltex}[tag=ParseStep_tree]
\newline
include::{modeltex}[tag=ParseStep_next]
++++

A *ParseStream* is a function that accepts an IVM, telling the parser what Ion
syntax follows, and returns an optional *ParseStep* whose absence denotes
end-of-file.  When present, the *ParseStep* contains the next *TSTree* from the
document, and a new *ParseStream* that can produce the rest of the document.

Note that necessary parser state, particularly its current position within the
document, must be passed through each *ParseStream* in the chain.
The details are specific to a particular *Parser* implementation (and perhaps to
the Ion format being read), so we don't define the *ParseStream* function here
and instead assume that it's provided by the *Parser*.

This concludes our semantics of the syntax and data models.
These are the inputs and outputs, respectively, of the expansion process, which
we will now explore.


[#expansion]
== Expansion

Circling back a bit, remember that our goal is to define how Ion expands the
abstract syntax trees produced by its parser to eliminate encoding features such
as symbol IDs and macros, thereby producing the document's application-facing data.

To begin, let's consider the state that must be maintained while expanding a
document.


=== The Encoding Environment

Directives effectively change the state of the decoder as it turns bytes on the
wire into application data.
We model this state, known as the __environment__, as follows:

[{denotation}]
++++
include::{modeltex}[tag=Environment]
++++

The encoding environment is a tuple with three components.

  * The *catalog* is a collection of shared modules provided to the
expansion process.  The manner by which modules are collected into a catalog is
outside the scope of the Ion specification, but we define the relevant semantics
in xref:catalog[xrefstyle=short].
  * We model the *current Ion version* as an Ion Version Marker.  This is used to
select a system symbol table, and gives us a way to alter the expansion
process based on Ion version.
  * We model the *current symbol table* as a sequence of symbol tokens defining
all current SIDs, starting from zero.

Following our practice for tuples, we'll define environment accessor functions.
Following computer science tradition, we use the Greek letter rho (stem:[\rho])
as the variable denoting environments.

[{denotation}]
++++
include::{modeltex}[tag=Environment_catalog]
\newline
include::{modeltex}[tag=Environment_IVM]
\newline
include::{modeltex}[tag=Environment_symbols]
++++


=== Symbol Token Expansion

We've now set enough context that we can implement the core of the expansion
process: replacing SIDs with text.  We introduce stem:[\cal X] ("`expand`") as
the base name of our various expansion functions, adding the input type as a
subscript.

[{denotation}]
++++
include::{modeltex}[tag=expand_SSymTok]
++++

Expansion of a syntactic symbol token requires the current environment.
If the symbol token already contains Unicode text, we simply wrap it with a
**SymTok**. Otherwise, the token is an integer SID, so we extract it via
stem:[\mbox{\it s\/}\mid_{\mbox{\scriptsize \mbox{\bf I}}}] and then look it up
in the current symbol table.
That requires a range check, raising an error if the SID exceeds the size of the
current symbol table.

To handle annotations, we'll need a recursive function expanding a sequence of
symbol tokens:

[{denotation}]
++++
include::{modeltex}[tag=expand_SSymTok*]
++++


=== Value Expansion

Turning to the generic syntax-tree domain, expansion of one *STree* is
(for Ion 1.0 at least) a simple pass-through:

[{denotation}]
++++
include::{modeltex}[tag=expand_STree]
++++

Note that this function returns **Value**{asterisk}.
This is more 1.1-preparedness, anticipating an additional branch for
E-expressions, which can return any number of items.

We expand a sequence of **STree**s by simple recursion:

[{denotation}]
++++
include::{modeltex}[tag=expand_STree*]
++++

Expanding **SValue** requires separate expansion of its annotations
and content, combining the results into a **Value**:

[{denotation}]
++++
include::{modeltex}[tag=expand_SValue]
++++

To expand *SContent* we must perform a type-switch.
The <<simple,simple domains>> **NullNull**, **Bool**, **Int**, and **String**
pass through easily by being re-wrapped as **Content**.
Anything else can contain symbol tokens to be expanded, and in each case we
downcast the content, call a type-specific function, then rewrap the result.

[{denotation}]
++++
include::{modeltex}[tag=expand_SContent]
++++

Expanding *SSymbol* requires distinguishing `symbol.null`:

[{denotation}]
++++
include::{modeltex}[tag=expand_SSymbol]
++++

Expanding lists and sexps is similar, with recursion on the sequence of elements:

[{denotation}]
++++
include::{modeltex}[tag=expand_SList]
\newline\newline
include::{modeltex}[tag=expand_SSexp]
++++

To handle **SStruct** with the same pattern, we'll use a helper to expand its
sequence of fields:

[{denotation}]
++++
include::{modeltex}[tag=expand_SStruct]
++++

Field expansion takes a bit more work.
We expand the field's name and tree using the appropriately-typed variants of
stem:[\cal X], but the latter can return multiple values (thank you, macros!).
To handle those, we need a little recursive function that creates a same-named
*Field* for each one.

[{denotation}]
++++
include::{modeltex}[tag=expand_SField]
++++

With that, expansion of a sequence of fields is simple recursion:

[{denotation}]
++++
include::{modeltex}[tag=expand_SField*]
++++

At this point we have fully denoted the expansion of syntax trees,
and can turn to the top level.


[id=eg_TE]
=== Top-Level Evaluation

TIP: Readers will likely find this section to be the most challenging of the
whole model. Don't hesitate to go through it in multiple passes.

After each *TSTree* produced by the parser is expanded, we must handle any
directives that result.  We refer to this phase as _evaluation_.

Evaluation of <<stx-top,top-level syntax>> requires us to use a new technique
in our model, since it involves changes to the environment.
In particular, the evaluation of a directive must produce a new environment,
but no application values.

Being purely functional, lambda calculus has no inherent concept of
"`imperative`" concerns such as order of evaluation and mutation of state.
The conventional way to model these in denotational semantics is via
_continuation-passing style_.  CPS is a design pattern that effectively emulates
those features in a purely functional manner by passing around _continuations_—functions
that model "`what happens next`" (that is, order of operations), and supplying
them with the computational state that results from each step of work.

We've managed to avoid continuations so far because Ion only needs these
features at top level, but we can no longer delay the inevitable.
Diving right in, let's examine the type of our continuation functions:

[{denotation}]
++++
include::{modeltex}[tag=TContinuation]
++++

This functional domain defines the shape of our top-level continuations.
In general, the arguments to a continuation are the products of a single
"`step`" of the overall computation, with regard to both typical procedural
results and the program's mutable state.
The job of a continuation is to combine those single-step results with
everything that happens _before and after_ that step, returning the result of
_the overall computation_.
Here, the *Environment* denotes the mutable state, the given **Value**s
are the single step results, and the resulting **Value**s denote the expansion
of the entire stream.

What does a single step look like?
Let's see how to expand a single top-level syntax tree, using overlines like
stem:[\overline{\cal E}] and stem:[\overline{rv}]
to indicate top-level functions and variables.

[{denotation}]
++++
include::{modeltex}[tag=TE_TSTree]
++++

When we encounter an IVM, we must reset the environment using a helper
function that we'll implement later.
We pass that to the continuation stem:[\kappa] along with an empty value
sequence, since the IVM produces no application data.
Here we've emulated mutation of the environment:
the current environment stem:[\rho] not passed to the continuation and is
therefore inaccessible to any remaining work it encapsulates.

All other top-level syntax is expanded using stem:[\cal X] and the
current environment stem:[\rho].
After expansion, we'll evaluate the resulting sequence of values.

To evaluate one top-level *Value*, we must check to see if it's an LST directive.

[{denotation}]
++++
include::{modeltex}[tag=TE_Value]
++++

Given an LST, we use its content, downcast to *Struct*, to produce the new
environment. Similar to the IVM case, _v_ is not passed along as application
data.
In the *else* clause, the expanded _v_ is application data, so we pass it to
the continuation along with the unaltered environment.

In accordance with continuation-passing style, stem:[\overline{\cal E}] never
returns results "`directly`": it always invokes the continuation stem:[\kappa]
with the next-current environment and any application values this step produces.
The continuation is responsible for assembling those results with everything
that happened previously, and anything that happens afterward, so the **Value**s
returned from the continuation
(and thus by stem:[\overline{\cal E}]) denote
the expansion of _the entire stream_.

This may become more clear by considering the evaluation of multiple top-level
values:

[{denotation}]
++++
include::{modeltex}[tag=TE_Value*]
++++

Here we have our most complex denotation yet, so let's break it down.

* The *if* and *then* clauses detect and handle the empty-sequence base case:
when given no top-level value, the environment is unchanged and no data
is produced.
* When the sequence is non-empty, we evaluate (with stem:[\overline{\cal E}])
its head (stem:[\overline{\mbox{\it v\/}^{\ast}}\!\downarrow_{0}]) using the
current environment stem:[\rho] and a locally-defined continuation, which will
be invoked with the _next_ environment (stem:[\rho_1]) and any application values
that result (stem:[\mbox{\it v\/}^{\ast}_{1}]).
* The first local continuation is responsible for evaluating the tail of the
stream (stem:[{\mbox{\it v\/}^{\ast}}\dagger1]) via
self-recursion on stem:[\overline{{\cal E}^{\ast}}], using whatever
environment resulted from expanding the head (stem:[\rho_1]).
* Those results are passed to a second local continuation, which receives the
environment in effect at the end of the tail (stem:[\rho_2]), and the tail's
expanded application data   (stem:[\mbox{\it v\/}^{\ast}_{2}]).
To produce the overall results, it calls the original continuation stem:[\kappa]
with that final environment and the results of this step: the concatenation of
the head and tail expansions
(stem:[\mbox{\it v\/}^{\ast}_{1}\S\mbox{\it v\/}^{\ast}_{2}]).

This demonstrates how local continuations are used to break a computation down
into steps, receiving incremental state and results, invoking the next step
of computation, then returning the final, overall results via a continuation
provided by the caller.

We still need to tie the top-level iteration to the parser by walking the
*ParseStream* it produces:

[{denotation}]
++++
include::{modeltex}[tag=TE_ParseStream]
++++

We start by invoking the current *ParseStream* _p_, passing it the current Ion
version so the parser knows how to interpret the next bytes of input.
The result is optional, and the *else* clause handles the EOF situation trivially.

The recursive clause is structurally similar to the one above, but here we get
the first syntax tree via stem:[\mbox{\it step}!\downarrow_{\mbox{tree}}] and
the next *ParseStream* via stem:[\mbox{\it step}!\downarrow_{\mbox{next}}].

With this method, we can evaluate an entire document, once we've converted it
into a parse stream, and acquired a boostrap environment and continuation.
That's the job of the *Evaluator* domain:

[{denotation}]
++++
include::{modeltex}[tag=Evaluator]
++++

As discussed in xref:parsing[xrefstyle=short], we are not defining parsing
functions in this article, so we can't define an entire *Evaluator*.
Instead, we can produce one, given a *Parser*:

[{denotation}]
++++
include::{modeltex}[tag=mk_Evaluator]
++++

This function produces another function in the *Evaluator* domain.
The resulting evaluator invokes
stem:[\overline{\cal E}_{\mbox{\scriptsize\bf ParseStream}}]
with an initial *ParseStream*, environment and continuation.
The former is provided by the *Parser* _p_, given a document _d_.
The initial environment is constructed from the given catalog _c_, in Ion 1.0 mode,
with the appropriate symbol table provided by a helper method.
The initial continuation, destined to receive the final expansion results, is
trivial: nothing needs to happen before or after the call to
stem:[\overline{\cal E}_{\mbox{\scriptsize\bf ParseStream}}],
so it discards the final environment stem:[\rho] and
returns the aggregated application data.

We've now concluded the denotation functions specifying the expansion of
symbol IDs and the handling of encoding directives in Ion 1.0 documents.
However, we've glossed over the mechanics of those directives by using some
helper functions we've yet to define.
The next sections will drill down into those details.


[#symtabs]
== Symbol Table Management

The handling of symbol tables brings us to some of the more lengthy functions
in this denotational model. The specified algorithms include a fair
amount of type-checking and default values to ensure that even nonsensical
directives have a well-defined and stable interpretation across implementations.
Put another way, the spec must leave nothing unspecified, so that whatever
nonsense appears inside an LST directive, all
implementations will behave the same way.


=== Ion Version Markers

Following an IVM, the current symbol table is set to the system symbols for the
given major and minor version of Ion.
This is straightforward to define.
First we define the content of the system module for a given Ion version:

[{denotation}]
++++
include::{modeltex}[tag=systemSymbols_1_0]
\newline
\newline
include::{modeltex}[tag=systemModule]
++++

(Apologies for the failure of our pretty printer, but you get the idea.)

The environment that follows an IVM retains the current environment's catalog,
but replaces the IVM and resets the symbol table to that of the new Ion version:

[{denotation}]
++++
include::{modeltex}[tag=Environment_after_IVM]
++++


=== Local Symbol Tables

The resulting environment after an LST directive is as follows, where
stem:[{\cal C}_{\mbox{\scriptsize LST}}] denotes the compilation of an LST
directive into a sequence of symbol tokens that will become the current symbol
table:

[{denotation}]
++++
include::{modeltex}[tag=Environment_after_LST]
++++

Here we see that the directive has the effect of retaining the current catalog
and Ion version, replacing only the current symbols.
// TODO Move this, it isn't illustrated by this code:
More importantly, we see that an LST directive is fully expanded using the
environment in effect when it begins.
The locally-declared symbols have no effect on the encoding of any part of the
enclosing struct.
Their scope only starts with the next top-level syntax tree.

TIP: At this point it may be worth reviewing the definitions of
stem:[\overline{\cal E}_{\mbox{\scriptsize\bf TSTree}}] and
stem:[\overline{\cal E}_{\mbox{\scriptsize\bf Value}}] and
in xref:eg_TE[xrefstyle=short].

At a high level, the compilation of an LST works as follows:

[{denotation}]
++++
include::{modeltex}[tag=SymToks_for_LST]
++++

Here we encounter the first of many null checks. In particular, top-level
`$ion_symbol_table::null.struct` is equivalent to `$ion_symbol_table::{}`.
Otherwise, we concatenate the imported symbols and the locally-declared symbols.
The former sequence includes any system symbols implicitly imported from the
current Ion version.

// TODO It might be interesting to show a proof that
//   C_LST({}, ρ) == SymToks_for_IVM(ρ↓IVM)

This function sidesteps the more heavy-duty work of turning the
directive into **SymTok**{asterisk} by delegating to helper functions
stem:[{\cal C}_{\mbox{\scriptsize\tt symbols}}] and
stem:[{\cal C}_{\mbox{\scriptsize\tt imports}}].
What follows is effectively a recursive-descent process over the
directive's fully-expanded *Struct*.


==== Compiling Local Symbols

Starting with the easy part, we compile the `symbols` field into
**SymTok**{asterisk}.
The input here is optional (that is, never more than one value) because struct
lookup stem:[\odot] raises an error if the field is repeated.

[{denotation}]
++++
include::{modeltex}[tag=declared_symbols]
++++

When there's no `symbols` declared, or the content not an actual *List*,
we return an empty sequence.
Otherwise, we compile the list's elements as follows:

[{denotation}]
++++
include::{modeltex}[tag=compile_symbols]
++++

This recursively compiles each list element into a *SymTok*.
For content that is a *String* and not null, we extract the Unicode and rewrap
it.  All other values produce `$0`.


==== Compiling Imported Symbols

We follow similar patterns for the `imports` field.
Remember that these results are expected to contain the appropriate system
symbols.

[{denotation}]
++++
include::{modeltex}[tag=imported_symbols]
++++

When `imports` are absent, we return the current system symbols (stem:[t^{\ast}]).
If `imports` is the symbol `$ion_symbol_table`, we return the entire
current symbol table.  When the content is a non-null *List*, we compile its
elements and append them to the current system symbols; otherwise the field
is malformed and we act is if it were absent.

Compiling the `imports` elements is similar to
stem:[{\cal C}_{\mbox{\scriptsize symbol}}^{\ast}] but each
element produces a list of tokens, not just one:

[{denotation}]
++++
include::{modeltex}[tag=compile_imports]
++++

As expected, we recurse through the elements of stem:[v^{\ast}], compiling
non-null **Struct**s and ignoring the rest.  To compile one such struct, we
delegate to stem:[\cal C_{\mbox{\scriptsize import}}] below.

Compiling an import-struct requires normalizing its meaningful fields,
checking presence, type, and nullness.
We'll use stem:[\cal N] as the name of normalization helper functions.
For `name` we return the text of non-null **String**s, normalizing everything
else to the empty string:

[{denotation}]
++++
include::{modeltex}[tag=normalize_name]
++++

For `version` we normalize to 1 when absent, malformed, or less than one:

[{denotation}]
++++
include::{modeltex}[tag=normalize_version]
++++

For `max_id` we normalize to stem:[\langle \rangle] when absent, malformed, or
less than zero:

[{denotation}]
++++
include::{modeltex}[tag=normalize_max_id]
++++

To compile one import-struct, we lookup and normalize the field values,
then produce a sequence of **SymTok**s retrieved from the catalog.

[{denotation}]
++++
include::{modeltex}[tag=compile_import]
++++

First, we ignore entries with malformed/absent names (which have been normalized
to empty), as well as the name `$ion`; you cannot explicitly import a system
symbol table.
Otherwise, _best_match_ (defined below) searches the catalog for the best match
to the name and version; it returns an optional *SharedModule* _s_.

If _m_ is present, a valid `max_id` was given, and we can use
whatever symbol table we've found, even if we found nothing with the given name.
Regardless, we adjust the number of symbols we return to align with the `max_id`
by using a helper function _adjust_length_ defined below.

When there's no valid `max_id` we require an exact match: if _s_ is present and
has the requested version _v_, we return its symbols.
Otherwise, we signal an error.

The functions to adjust the sequence length are straightforward.
_symbol_padding_ produces a sequence of _n_ copies of `$0`, and _adjust_length_
takes a **SymTok**{asterisk} and either truncates it or pads it with `$0`.

[{denotation}]
++++
include::{modeltex}[tag=symbol_padding]
\newline\newline
include::{modeltex}[tag=adjust_length]
++++

Here, _seq_truncate_ returns the first _n_ entries from a sequence; in other
words, it returns what stem:[\dagger] would discard.


[id=catalog]
=== Modules, Shared Modules, and Catalogs

In general, a *Module* is anonymous and can be associated with various names in
different contexts. Inherently, it consists of a specification version (that is,
the version of Ion that defines its meaning), and--for now--a sequence of
exported symbols.

[{denotation}]
++++
include::{modeltex}[tag=Module]
\newline
include::{modeltex}[tag=Module_specVersion]
\newline
include::{modeltex}[tag=Module_symtab]
++++

A shared module wraps a module with a specific name and a version:

[{denotation}]
++++
include::{modeltex}[tag=SharedModule]
\newline
include::{modeltex}[tag=SharedModule_name]
\newline
include::{modeltex}[tag=SharedModule_version]
\newline
include::{modeltex}[tag=SharedModule_module]
\newline
include::{modeltex}[tag=SharedModule_symtab]
++++

:fn-sst-issue: footnote:[This needs error handling similar to local symbol \
tables.  See xref:iss-sst[xrefstyle=short].]

Ion defines a standard serialization of shared symbol tables, which we can
easily compile{fn-sst-issue} into shared modules:

[{denotation}]
++++
include::{modeltex}[tag=is_SST]
\newline\newline
include::{modeltex}[tag=compile_SST]
++++


A catalog is just a sequence of shared modules.

[{denotation}]
++++
include::{modeltex}[tag=Catalog]
++++

What's tricky is implementing the "`best match`" semantics required by the Ion
specification: if there's no exact match to the requested version, we must
return the largest version available.
First, we need to unwrap the Catalog:

[{denotation}]
++++
include::{modeltex}[tag=best_match_Catalog]
++++

Having done that, we recursively walk the module sequence, returning either an
exact match for the name/version, or the highest version, or nothing.

[{denotation}]
++++
include::{modeltex}[tag=best_match_Module]
++++

There are several cases to account for here.
If the current entry (_s_) has a different name, we return the best-match from
the recursive tail (stem:[s^{\ast}_1]).
Otherwise, the name matches, so if the version matches _or_ no match in the
tail is present, we return the current entry.
Otherwise, if the best-match in the tail (stem:[s^{\ast}_1!]) is an
exact match, or has a larger version than the current entry, we return that.
Otherwise, the current entry is the best we've got.



[#issues]
== Known Issues

This denotational model is currently defective with respect to the published Ion
specification in the following ways.


[id=iss-structorder]
=== Improper ordering of struct fields

Ion structs are unordered, but this model currently denotes them as sequences.
This means that the same field-values in different order will _not_ be
equivalent per lambda calculus.  Denoting this properly is possible (by
constructing the set of all permutations) but requires a fair amount of code.


[id=iss-symeq]
=== Improper equivalence of unknown shared symbols

The model maps all unknown shared symbols to `$0` and therefore they are all
equivalent to the model.  This is incorrect per
https://amazon-ion.github.io/ion-docs/docs/symbols.html#data-model[the spec],
which says:

[quote]
____
For symbols defined from shared symbol table imports, [unknown] symbols are
equivalent only if all of the following hold:

* The name of the table that the symbols were imported from is the same string.
* The position in the table that the symbols were imported from is the same
spot.
____

https://amazon-ion.github.io/ion-docs/docs/symbols.html#symbol-zero[Further],

[quote]
____
It is important to note that `$0` is only semantically equivalent to itself and
to locally-declared SIDs with unknown text. It is not semantically equivalent to
SIDs with unknown text from shared symbol tables, so replacing such SIDs with
`$0` is a destructive operation to the semantics of the data.
____

To handle this, *SymTok* needs a subdomain to capture the SST and index.


[id=iss-sst]
=== Shared symbol table compilation is weak

We don't type check the inputs, which "`crashes`" the math when given bad data.
This doesn't really affect the important parts of the model.

On a related note, catalog construction should reject duplicate keys, so we
don't imply anything about selection criteria.

=== Repeated text in SSTs should become undefined

[quote]
____
When mapping from string to symbol ID, there may be multiple associated IDs (the
same string could appear twice as children of the symbols field).
Implementations MUST select the lowest known ID, and all other associated IDs
MUST be handled as if undefined.
____

It's a bit unclear why this clause exists, but the model doesn't specify it.


[appendix]
== The Full Denotation

=== Legend

Here we catalog various glyphs, conventions, and low-level functions used
throughout the denotation.

// TODO (?) IF; LET; LETREC; AND/OR/NOT

[cols="^.^1,3,5"]
|===
| Notation | Meaning | Description

|stem:[\equiv]
|Definition
|Indicates that two equations or notations are defined to be equivalent

|stem:[\mbox{\it{in}\small\bf Domain}(v)]
|Union domain injection
|Wraps or lifts a value _v_ into a union domain.

|stem:[v\mid_{\mbox{\scriptsize\bf Domain}}]
|Union domain projection
|Unwraps or lowers a union domain value into a component domain.

|stem:[\mbox{\it name}^{\ast}]
|Sequence indicator
|Superscript asterisk decorates a _name_ to indicate that holds, processes,
or returns a sequence of things

|stem:[\langle ... \rangle]
|Sequence construction
|Delimits the elements of a sequence

|stem:[\#]
|Sequence length
|Returns the number of elements in a sequence.
stem:[\#\langle v_1 ... v_n \rangle ~\equiv~ n]

|stem:[\S]
|Sequence concatenation
|Joins two sequences.
stem:[\langle v_0 ... v_m \rangle \S \langle v_{m+1} ... v_n \rangle ~\equiv~
\langle v_0 ... v_n \rangle]

|stem:[\downarrow]
|Sequence/tuple element selection
|Extracts one element of a sequence.
stem:[\langle v_0 ... v_n \rangle\!\downarrow_i ~\equiv~ v_i]

Also used to extract a field from a tuple by name.

|stem:[\dagger]
|Sequence "`tail`" function
|Returns elements from the end of a sequence.
stem:[\langle v_0 ... v_n \rangle \dagger i ~\equiv~ \langle v_i ... v_n \rangle]

|stem:[\interrobang]
|Option presence check
|Returns true iff the option contains an element.
stem:[v\interrobang ~\equiv~ \#v = 1]

|stem:[!]
|Option element selection
|Returns the sole element of an option.
stem:[v!  ~\equiv~  v \downarrow_0]

|stem:[\cong]
|Symbol matching
|Compares an symbolic element to a Unicode string

|stem:[\odot]
|Struct lookup
|Retrieves value(s) from a struct by Unicode field name

|stem:[\cal X]
|Expansion function
|Transforms syntax trees into Ion data model elements

|stem:[\cal E]
|Evaluation function
|Evaluates directives discovered at top-level

|stem:[\cal C]
|Compilation function
|Transforms expanded data of a directive into its denotation/meaning

|stem:[\cal N]
|Normalization function
|Normalizes the value of a field

|stem:[\kappa]
|Greek letter kappa
|Variable name used for continuations

|stem:[\rho]
|Greek letter rho
|Variable name used for environments

|===

=== Domains

[{denotation}]
++++
include::{modeltex}[tag=domains]
++++

=== Constants

[{denotation}]
++++
include::{modeltex}[tag=constants]
++++

=== Functions

[{denotation}]
++++
include::{modeltex}[tag=functions]
++++
